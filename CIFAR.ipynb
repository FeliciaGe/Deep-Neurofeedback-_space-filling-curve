{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "epochs = 10\n",
    "hidden_size = 20\n",
    "intermediate_size = 128\n",
    "log_interval = 10\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=True, download=True,\n",
    "                     transform=transforms.ToTensor()),\n",
    "    batch_size=512, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=512, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 32, intermediate_size)\n",
    "\n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(intermediate_size, hidden_size)\n",
    "        self.fc22 = nn.Linear(intermediate_size, hidden_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(hidden_size, intermediate_size)\n",
    "        self.fc4 = nn.Linear(intermediate_size, 8192)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        # import pdb; pdb.set_trace()\n",
    "        out = out.view(out.size(0), 32, 16, 16)\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.sigmoid(self.conv5(out))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "        if epoch == epochs and i == 0:\n",
    "            n = min(data.size(0), 8)\n",
    "            comparison = torch.cat([data[:n],\n",
    "                                   recon_batch[:n]])\n",
    "            save_image(comparison.data.cpu(),\n",
    "                       'snapshots/conv_vae/reconstruction_' + str(epoch) +\n",
    "                       '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:141: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:147: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2124.020020\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2119.039795\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2109.692871\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2135.869629\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 2137.454590\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2104.304688\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 2132.151611\n",
      "Train Epoch: 1 [35840/50000 (71%)]\tLoss: 2124.375732\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 2117.572998\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 2104.397217\n",
      "====> Epoch: 1 Average loss: 2125.4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:158: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:160: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 2118.7556\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2077.984131\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 2014.935669\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 2019.218384\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 2006.380981\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 2040.215332\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2014.866089\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 2024.642090\n",
      "Train Epoch: 2 [35840/50000 (71%)]\tLoss: 2000.441406\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1949.568970\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1957.253540\n",
      "====> Epoch: 2 Average loss: 2003.9983\n",
      "====> Test set loss: 1961.0876\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1960.758179\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1955.104858\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1945.156006\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1943.620728\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1988.982178\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1958.351318\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1945.795898\n",
      "Train Epoch: 3 [35840/50000 (71%)]\tLoss: 1934.186646\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1953.200684\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1967.047729\n",
      "====> Epoch: 3 Average loss: 1952.5304\n",
      "====> Test set loss: 1923.2000\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1914.276611\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 1950.772705\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 1941.934082\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 1946.125244\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 1946.177246\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1931.663696\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 1928.661011\n",
      "Train Epoch: 4 [35840/50000 (71%)]\tLoss: 1945.246216\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 1925.538818\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 1923.422974\n",
      "====> Epoch: 4 Average loss: 1934.1910\n",
      "====> Test set loss: 1907.0654\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1897.759033\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 1924.934570\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 1924.869629\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 1907.392212\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 1923.529541\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1934.950562\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 1905.708130\n",
      "Train Epoch: 5 [35840/50000 (71%)]\tLoss: 1911.998047\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 1909.243164\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 1923.095093\n",
      "====> Epoch: 5 Average loss: 1918.9950\n",
      "====> Test set loss: 1894.0706\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1899.095825\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 1909.384766\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 1918.952637\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 1905.979614\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 1914.527710\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1922.861084\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 1914.647827\n",
      "Train Epoch: 6 [35840/50000 (71%)]\tLoss: 1900.763306\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 1912.634399\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 1881.846924\n",
      "====> Epoch: 6 Average loss: 1911.3665\n",
      "====> Test set loss: 1887.8920\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1896.079102\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 1915.401123\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 1916.543335\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 1896.538086\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 1905.324219\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1907.493042\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 1901.786255\n",
      "Train Epoch: 7 [35840/50000 (71%)]\tLoss: 1915.177979\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 1913.442261\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 1910.337402\n",
      "====> Epoch: 7 Average loss: 1904.1914\n",
      "====> Test set loss: 1882.2296\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1877.743652\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 1902.338745\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 1900.583496\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 1914.817383\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 1907.086792\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1911.576660\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 1899.913818\n",
      "Train Epoch: 8 [35840/50000 (71%)]\tLoss: 1890.366455\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 1886.334961\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 1894.687256\n",
      "====> Epoch: 8 Average loss: 1898.8026\n",
      "====> Test set loss: 1878.1864\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1874.585083\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 1909.241455\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 1906.395752\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 1898.196045\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 1899.336182\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1889.827393\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 1887.764893\n",
      "Train Epoch: 9 [35840/50000 (71%)]\tLoss: 1899.492310\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 1904.731079\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 1896.833374\n",
      "====> Epoch: 9 Average loss: 1894.7667\n",
      "====> Test set loss: 1875.6172\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1865.772949\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 1902.968140\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 1910.784546\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 1891.900269\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 1903.868774\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1876.686279\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 1909.246582\n",
      "Train Epoch: 10 [35840/50000 (71%)]\tLoss: 1883.187134\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 1880.952393\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 1894.394043\n",
      "====> Epoch: 10 Average loss: 1891.2430\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'snapshots/conv_vae/reconstruction_10.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e35da4acc2ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e35da4acc2ac>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    165\u001b[0m             save_image(comparison.data.cpu(),\n\u001b[1;32m    166\u001b[0m                        \u001b[0;34m'snapshots/conv_vae/reconstruction_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                        '.png', nrow=n)\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'snapshots/conv_vae/reconstruction_10.png'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    if epoch == epochs:\n",
    "        sample = Variable(torch.randn(64, hidden_size))\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.data.view(64, 3, 32, 32),\n",
    "                   './sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexinyue/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './cifar_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./cifar_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Variable(torch.randn(64, hidden_size))\n",
    "sample = model.decode(sample).cpu()\n",
    "save_image(sample.data.view(64, 3, 32, 32),'Hello.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
